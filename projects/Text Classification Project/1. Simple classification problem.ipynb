{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Imports and Load Data\n",
    "For this exercise we'll be using the **SMSSpamCollection** dataset from [UCI datasets](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) that contains more than 5 thousand SMS phone messages.<br>You can check out the [**sms_readme**](../TextFiles/sms_readme.txt) file for more info.\n",
    "\n",
    "The file is a [tab-separated-values](https://en.wikipedia.org/wiki/Tab-separated_values) (tsv) file with four columns:\n",
    "> **label** - every message is labeled as either ***ham*** or ***spam***<br>\n",
    "> **message** - the message itself<br>\n",
    "> **length** - the number of characters in each message<br>\n",
    "> **punct** - the number of punctuation characters in each message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/smsspamcollection.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values:\n",
    "Machine learning models usually require complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a quick look at the *ham* and *spam* `label` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>We see that 4825 out of 5572 messages, or 86.6%, are ham.<br>This means that any machine learning model we create has to perform **better than 86.6%** to beat random chance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data:\n",
    "Since we're not ready to do anything with the message text, let's see if we can predict ham/spam labels based on message length and punctuation counts. We'll look at message `length` first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This dataset is extremely skewed. The mean value is 80.5 and yet the max length is 910. Let's plot this on a logarithmic x-axis.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['length'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['length'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>It looks like there's a small range of values where a message is more likely to be spam than ham.</font>\n",
    "\n",
    "Now let's look at the `punct` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean        4.177495\n",
       "std         4.623919\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         6.000000\n",
       "max       133.000000\n",
       "Name: punct, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['punct'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xscale('log')\n",
    "bins = 1.5**(np.arange(0,15))\n",
    "plt.hist(df[df['label']=='ham']['punct'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['punct'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This looks even worse - there seem to be no values where one would pick spam over ham. We'll still try to build a machine learning classification model, but we should expect poor results.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Split the data into train & test sets:\n",
    "\n",
    "If we wanted to divide the DataFrame into two smaller sets, we could use\n",
    "> `train, test = train_test_split(df)`\n",
    "\n",
    "For our purposes let's also set up our Features (X) and Labels (y). The Label is simple - we're trying to predict the `label` column in our data. For Features we'll use the `length` and `punct` columns. *By convention, **X** is capitalized and **y** is lowercase.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features\n",
    "There are two ways to build a feature set from the columns we want. If the number of features is small, then we can pass those in directly:\n",
    "> `X = df[['length','punct']]`\n",
    "\n",
    "If the number of features is large, then it may be easier to drop the Label and any other unwanted columns:\n",
    "> `X = df.drop(['label','message'], axis=1)`\n",
    "\n",
    "These operations make copies of **df**, but do not change the original DataFrame in place. All the original data is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature and Label sets\n",
    "X = df[['length','punct']]  # note the double set of brackets\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional train/test/split arguments:\n",
    "The default test size for `train_test_split` is 30%. Here we'll assign 33% of the data for testing.<br>\n",
    "Also, we can set a `random_state` seed value to ensure that everyone uses the same \"random\" training & testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (3900, 2)\n",
      "Testing Data Shape:  (1672, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print('Training Data Shape:', X_train.shape)\n",
    "print('Testing Data Shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass these sets into a series of different training & testing algorithms and compare their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "# Train a Logistic Regression classifier\n",
    "One of the simplest multi-class classification tools is [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Scikit-learn offers a variety of algorithmic solvers; we'll use [L-BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1404   44]\n",
      " [ 219    5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Create a prediction set:\n",
    "predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1404</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1404    44\n",
       "spam   219     5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can make the confusion matrix less confusing by adding labels:\n",
    "df = pd.DataFrame(metrics.confusion_matrix(y_test, predictions), index=['ham','spam'], columns=['ham','spam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>These results are terrible! More spam messages were confused as ham (241) than correctly identified as spam (5), although a relatively small number of ham messages (46) were confused as spam.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.91      1448\n",
      "        spam       0.10      0.02      0.04       224\n",
      "\n",
      "    accuracy                           0.84      1672\n",
      "   macro avg       0.48      0.50      0.48      1672\n",
      "weighted avg       0.76      0.84      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8427033492822966\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This model performed *worse* than a classifier that assigned all messages as \"ham\" would have!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a naïve Bayes classifier:\n",
    "One of the most common - and successful - classifiers is [naïve Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1438   10]\n",
      " [ 224    0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = nb_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>The total number of confusions dropped from **287** to **256**. [241+46=287, 246+10=256]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.92      1448\n",
      "        spam       0.00      0.00      0.00       224\n",
      "\n",
      "    accuracy                           0.86      1672\n",
      "   macro avg       0.43      0.50      0.46      1672\n",
      "weighted avg       0.75      0.86      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8600478468899522\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Better, but still less accurate than 86.6%</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a support vector machine (SVM) classifier\n",
    "Among the SVM options available, we'll use [C-Support Vector Classification (SVC)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(gamma='auto')\n",
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1515   78]\n",
      " [ 131  115]]\n"
     ]
    }
   ],
   "source": [
    "predictions = svc_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>The total number of confusions dropped even further to **209**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.94      1593\n",
      "        spam       0.60      0.47      0.52       246\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1839\n",
      "   macro avg       0.76      0.71      0.73      1839\n",
      "weighted avg       0.88      0.89      0.88      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886351277868\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>And finally we have a model that performs *slightly* better than random chance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you should be able to load a dataset, divide it into training and testing sets, and perform simple analyses using scikit-learn.\n",
    "## Next up: Feature Extraction from Text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
